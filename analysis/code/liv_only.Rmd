---
title: "Simulation of Latent Instrumental Variables"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r, echo = FALSE}
set.seed(1234)
```

As a first step towards our own LIV estimation for the GfK project, I propose to code up:

Ebbes, P., Wedel, M., BÃ¶ckenholt, U., & Steerneman, T. (2005). Solving and testing for regressor-error (in) dependence when no instrumental variables are available: With new evidence for the effect of education on income. *Quantitative Marketing and Economics*, 3(4), 365-392. To the extent possible, I adhere to the notation in that paper.

# 2.0 LIV 

# 2.1 Simulate data

```{r}

sim_data <- function(rho = .5, N = 1000, pi_vals = c(-.3, .7), coef_x = 3) {
  # Number of observations
  #N = 1000
  
  # Coefficients on latent instruments
  #pi_vals = c(-.3, .7) 
  
  # Class probabilities
  p = c(.7, .3)
  
  # Assert the probs sum to 1
  stopifnot(sum(p)==1)
  
  # Number of latent instruments
  k = length(pi_vals)
  
  # Correlation matrix
  R = matrix(c(1, rho,
                  rho, 1), ncol=2)
  # Standard deviations
  S <- c(sqrt(.5), sqrt(.5))
  
  cor2cov <- function(R, S) {
   sweep(sweep(R, 1, S, "*"), 2, S, "*")
  }
  
  Sigma = cor2cov(R, S)
  
  # Draws from the Var-Covar Matrix
  
  library(MASS)
  set.seed(1234)
  errorterm = mvrnorm(n = N, mu = c(0,0), Sigma =Sigma)
  
  cor(errorterm)
  cov(errorterm)
  
  z <- sample(1:k, N, replace = T, prob = p)
  cbind(class = 1:k, frequency = table(z), prob = table(z)/sum(table(z)))
  
  # Simulate data
  x = pi_vals[z] + errorterm[,2]
  
  y = 1 + coef_x * x + errorterm[,1]
  
  return(list(data = data.frame(y, x, z), pi_vals=pi_vals, coef_x = coef_x))


}
```

## 2.2 Estimate using OLS

Bias when `rho = .5`

```{r}
# bias:
out=sim_data(rho = 0.95, coef_x=.5, pi_vals=c(-1,2))
hist(out$data$x, breaks=100)
summary(lm(y~1+x, data = out$data))
```

```{r}
# recovery by package
out=sim_data(rho = .3, coef_x=.5, pi_vals=c(-1,2), N = 10000)
#hist(out$data$x, breaks=100)
#out$data$y = out$data$y
library(REndo)

l <- latentIV(y~x, data = out$data)
summary(l)

```

summary(l)


No bias when `rho = 0`

```{r}
# no bias:
out=sim_data(rho = 0, coef_x=.5, pi_vals=c(-1,2))
summary(lm(y~1+x, data = out$data))
```

## 2.3 Recovery using MLE a la Ebbes et al. 

### Log-likelihood

```{r}

library(mvtnorm)

map_pars <- function(pars) {
  beta0 = pars[1]
  beta1 = pars[2]
  
  # Covariance/correlation structure
  uchol = diag(2)
  uchol[1,1] <- pars[3]
  uchol[1,2] <- pars[4]
  uchol[2,2] <- pars[5]
  
  sigma <- crossprod(uchol)
  
  # class memberships
  prob <- exp(pars[6])/(1+exp(pars[6]))
  
  # instrument coefficients
  #lambdas <- double(2)
  #lambdas[1] <- pars[7]
  #lambdas[2] <- pars[7] + exp(pars[8])
  lambdas = pars[7:8]  
  return(list(beta0=beta0, beta1=beta1, uchol=uchol, sigma=sigma, prob=prob, lambdas=lambdas))
}

llik <- function (params) {
  
  pars=map_pars(params)
  
  lambdas = pars$lambdas
  beta0=pars$beta0
  beta1=pars$beta1
  prob=pars$prob
  varcov=pars$sigma
  
  y_pred1 = beta0 + beta1 * lambdas[1]
  y_pred2 = beta0 + beta1 * lambdas[2]
  
  llik1 = dmvnorm(cbind(y-y_pred1, x-lambdas[1]), mean=c(0,0), sigma=varcov, log=T)
  llik2 = dmvnorm(cbind(y-y_pred2, x-lambdas[2]), mean=c(0,0), sigma=varcov, log=T)

  max.AB = pmax(log(prob) + llik1, log(1-prob) + llik2)
  
  llik_lse = sum(max.AB + log(prob * exp(llik1 - max.AB) + (1-prob) * exp(llik2-max.AB)))

  return(-llik_lse)
  
}

```

### Estimation
```{r}
library(stats4)

# Simulate data
set.seed(999)
out=sim_data(rho = .3, coef_x=.5, pi_vals=c(-1,2), N = 10000)

y=out$data$y
x=out$data$x
z=out$data$z
pi_vals=out$pi_vals

params = c(0, 1, 1, 0, 1, 0, 0, 0)

MLE = optimx(params, fn = llik, method = 'Nelder-Mead', hessian = TRUE, itnmax = 10000, 
        control = list(trace = 0, dowarn = FALSE))
MLE$p2

```
