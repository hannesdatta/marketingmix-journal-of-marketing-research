---
title: "Simulation of Latent Instrumental Variables"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r, echo = FALSE}
set.seed(1234)
```

As a first step towards our own LIV estimation for the GfK project, I propose to code up:

Ebbes, P., Wedel, M., Böckenholt, U., & Steerneman, T. (2005). Solving and testing for regressor-error (in) dependence when no instrumental variables are available: With new evidence for the effect of education on income. *Quantitative Marketing and Economics*, 3(4), 365-392. To the extent possible, I adhere to the notation in that paper.

# 2.0 LIV 

# 2.1 Simulate data

```{r}
set.seed(1234)

#Simulate data
sim_data <- function(rho = .3,
                     N = 100,
                     latent_instruments = list(list(
                       pi = c(-1, 2),
                       p = c(.3, .7),
                       beta = .5
                     ))) {
  
  # Correlation matrix
  n=length(latent_instruments)+1
  R = diag(n)
  R[-1,1]<-rho
  R[1,-1]<-rho
  
  # Standard deviations
  S <- rep(sqrt(.5), n)
  
  cor2cov <- function(R, S) {
   sweep(sweep(R, 1, S, "*"), 2, S, "*")
  }
  
  Sigma = cor2cov(R, S)
  
  # Draws from the Var-Covar Matrix
  library(MASS)
  errorterm = mvrnorm(n = N, mu = rep(0, n), Sigma = Sigma)
  
  #Compute endogenous regressor (uniformly distributed from min(unif) to max(unif)
  #cor(errorterm)
  #cov(errorterm)

  instr = do.call('cbind', lapply(latent_instruments, function(liv) {
    # Assert the probs sum to 1
    stopifnot(sum(liv$p)==1)
  
    # Number of latent instruments
    k = length(liv$pi)
  
    # Draw class memberships
    z <- sample(1:k, N, replace = T, prob = liv$p)
    
    #cbind(class = 1:k, frequency = table(z), prob = table(z)/sum(table(z)))

    # Simulate data
    x <- liv$pi[z]
    return(x)
    }))

  instr = instr+errorterm[,-1]
  
  colnames(instr) <- paste0('x', 1:length(latent_instruments))
  
  liv_betas = unlist(lapply(latent_instruments, function(x) x$beta))
  
  
  
  y = 1 + instr%*%cbind(liv_betas) + errorterm[,1]
  
  colnames(y) <- 'y'
  return(list(data=data.frame(y,instr),rho, N, latent_instruments))

}
```

## 2.2 Comparison Latent IV with OLS

```{r include=FALSE}
# Startup cluster

library(parallel)
init <- function() {
  library(REndo)
  library(data.table)
}
cl <- makePSOCKcluster(4)
clusterExport(cl, 'init')

```

```{r message=FALSE, warning=FALSE}
set.seed(1984)
reps = 100
data=lapply(1:reps, function(x) sim_data(rho = 0 ))

clusterEvalQ(cl, init())

out = clusterApplyLB(cl, data, function(dt) {
  ols = lm(y ~ 1 + x1, data = dt$data)
  liv <- latentIV(y ~ x1, data = dt$data)
  return(cbind(
    ols = ols$coefficients[2],
    liv = liv$coefficients[2]
  ))
})


res = do.call('rbind',out)

colMeans(res)
apply(res,2, sd) # in the confidence bounds!

hist(drop(res[,2]),breaks=100)
#hist(data[[1]]$data$x1)



```


No bias when `rho = 0`

```{r}
# no bias:
out=sim_data(rho = 0, coef_x=.5, pi_vals=c(-1,2))
summary(lm(y~1+x, data = out$data))
```

## 2.3 Recovery using MLE a la Ebbes et al. 

### Estimation
```{r}
library(stats4)
library(optimx)

# Simulate data
set.seed(999)
out=sim_data(rho = .3, coef_x=.5, pi_vals=c(-1,2), N = 100)
source('liv_llik.R')

y=out$data$y
x=out$data$x
z=out$data$z
pi_vals=out$pi_vals

params = c(0, 1, 1, 0, 1, 0, 1, 2)

# without simulated maximum likelihood
MLE = optimx(params, fn = llik, method = 'Nelder-Mead', hessian = TRUE, itnmax = 10000, 
        control = list(trace = 0, dowarn = FALSE))
unlist(MLE)

llik(params, sim=T)

# with simulated maximum likelihood
MLE2 = optimx(params, fn = llik, method = 'Nelder-Mead', hessian = TRUE, itnmax = 10000, 
        control = list(trace = 0, dowarn = FALSE), sim=T)
unlist(MLE2)


```


```{r}
# try copulas

#Gewone OLS zonder EC: Onze X’s; correlatie opbrengen met error term; Gaussian werkt (?) (yt, xt; endogeniteit aanmaken; xt, delta xt opnemen, kijken of het nog werkt)
#Wel toewerken naar EC
out=sim_data(rho = .3, coef_x=.5, pi_vals=c(-1,2), N = 10000)
out=sim_data(rho = .5, coef_x=.5, pi_vals=c(-2,2), N = 10000, type = 'copula')

make_copula <- function(x, increment = .001) {
		if (length(unique(x))==1) return(as.numeric(rep(NA, length(x))))
		return(ifelse(ecdf(x)(x)==1, qnorm(1-increment), qnorm(ecdf(x)(x))))
}
data=out$data
data$copula <- make_copula(data$x)

hist(data$x)

shapiro.test(sample(data$x,5000))


summary(lm(y~1+x,data=data))
summary(lm(y~1+x+copula,data=data))

# fantastic!

```

```{r}
# recovery via Latent IVs?

y=data$y
x=data$x

params = c(0, 1, 1, 0, 1, 0, 1, 2)

# without simulated maximum likelihood
MLE = optimx(params, fn = llik, method = 'Nelder-Mead', hessian = TRUE, itnmax = 10000, 
        control = list(trace = 0, dowarn = FALSE))
unlist(MLE)

summary(lm(y~1+x,data=data))
summary(lm(y~1+x+copula,data=data))

y=data$y
x=data$x


#z=out$data$z
#pi_vals=out$pi_vals

# use copula in estimation?

params = c(0, 1, 1, 0, 1, 0, 1, 2)

MLE = optimx(params, fn = llik, method = 'Nelder-Mead', hessian = TRUE, itnmax = 10000, 
        control = list(trace = 0, dowarn = FALSE))
unlist(MLE)

#llik(params, sim=T)

