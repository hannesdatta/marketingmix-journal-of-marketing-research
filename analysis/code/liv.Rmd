---
title: "Simulation of Latent Instrumental Variables"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r, echo = FALSE}
set.seed(1234)
```

As a first step towards our own LIV estimation for the GfK project, I propose to first "learn" LIV in the spirit of 

Zhang, J., Wedel, M., & Pieters, R. (2009). Sales effects of attention to feature advertisements: a Bayesian mediation analysis. *Journal of Marketing Research*, 46(5), 669-681.

See https://scholar.rhsmith.umd.edu/sites/default/files/wedel/files/web_appendix_jmr-07-0313.r2_final.doc?m=1467366849 for their notes, which we also discussed with Michel in Sydney.

In #1, I translate their data simulation code to R.
In #2, I try to recover the true parameters [which does not work yet]

# 1.0 Simulating data

## 1.1 Setup

```{r}
# Number of latent instrument classes
k = 2 

# Number of observations
N = 1000
```

## 1.2 Latent discrete instrument

```{r}
# Class probabilities
p <- double(k)
p[1] <- rbeta(1,1,1) 
p[2] <- 1-p[1]
p
```

```{r}
# Simulate actual class memberships
V <- sample(1:k, N, replace = T, prob = p)

# Frequencies and empirical probabilities
cbind(class = 1:k, frequency = table(V), prob = table(V)/sum(table(V)))
```

```{r}
# Distribution of latent instrument coefficients
set.seed(1234)
lambda <- double(k)

precision = .0001

# note: Winbugs uses dnorm(mu, tau), where tau is the precision, and 
# the relationship between tau and SD is SD = 1/sqrt(tau).

lambda[1] <- rnorm(1, 0, 1/sqrt(precision))

# Require draw from censored normal
rcnorm <- function (n, mean = 0, sd = 1, left = -Inf, right = Inf) 
{
    rval <- rnorm(n) * sd + mean
    pmax(pmin(rval, right), left)
}

lambda[2] <- lambda[1] + rcnorm(1, mean = 0, sd = 1/sqrt(precision), left = 0+.0001)

# The chosen distribution by Zhang et al. is weird (mostly the same coefficients); hard-code to two other values.

lambda <- c(-5,3)

lambda
```
## 1.3 Data

```{r}
# Generate remaining variables
set.seed(1263)

# mediated pregressor
x = rnorm(N)

# control variable
z = rnorm(N)

```

```{r}
# Simulate mediator
set.seed(2020)

alpha = 1

mu_m <- alpha * x + lambda[V]

xsi = c(1,1) # SD of error term of Y and M

err2 = rnorm(N, 0, xsi[2])
m <- mu_m + err2

hist(m)

# non-normality (bimodality), as desired
```

## 1.4 Dependent variable

```{r}
# Simulate Y

beta = c(.5,.2,.3)
gamma = .4
rho = .4 # endogenous correlation

mu_y = beta[1] + beta[2]*mu_m + beta[3] * z + gamma * x + rho * (m - mu_m)

set.seed(2)
err1 = rnorm(N, 0, xsi[1])

y = mu_y + err1

# Verify OLS works
ols <- lm(y~1+m + z + x)
summary(ols)

# ...but: biased
```

```{r}
# Simulate "bias" for several rhos between 0 and 1.

beta = c(.5,.2,.3)
gamma = .4
rhos = seq(from = 0, to = 1, length.out=20)

estimates = lapply(rhos, function(rho) {

  mu_y = beta[1] + beta[2]*mu_m + beta[3] * z + gamma * x + rho * (m - mu_m)

  set.seed(2)
  err1 = rnorm(N, 0, xsi[1])

  y = mu_y + err1

  model = lm(y~1+m + z + x)
  return(model$coefficients)
})

res <- do.call('cbind', estimates)
colnames(res) <- paste0('rho=', rhos)
t(res)

# true values in red
plot(y=res['m',],x=rhos,type='l', main = 'Coefficient on M')
abline(h=beta[2], col = 'red')

plot(y=res['x',],x=rhos,type='l', main = 'Coefficient on X')
abline(h=gamma, col = 'red')

```

--> OLS is biased for high rhos.

# 2.0 Recovery of true parameters using LIV estimation

## 2.1 Try out MLE and compare w/ OLS

```{r}

# likelihood function for normal distribution
# with two unknowns
neg_log_lik_gaussian <- function(pars) {
  beta = pars[1:3]
  gamma = pars[4]
  xsi = exp(pars[5])/(1+exp(pars[5]))
  #rho = exp(pars[5])
  
  y_pred = beta[1] + beta[2]*m + beta[3] * z + gamma * x #+ rho * (m - mu_m)

  -sum(dnorm(y-y_pred, mean=0, sd=xsi, log=TRUE))
}

neg_log_lik_gaussian(c(double(4),1))

library(stats4)

MLE = optim(c(0,0,0,0,1), fn = neg_log_lik_gaussian,
            method = 'L-BFGS-B',
            lower = .00001)

# Comparison

data.frame(OLS=ols$coefficients, MLE = rev(rev(MLE$par)[-1]))

# looks good!
```

## 2.2 Draft MLE estimator for LIV
```{r}
set.seed(634123)
p_draws <- runif(N)

neg_log_lik_gaussian_liv <- function(pars) {
  beta = pars[1:3]
  gamma = pars[4]
  xsi = double(2)
  xsi[1] = exp(pars[5])/(1+exp(pars[5]))
  
  alpha = pars[6]
  lambdas = pars[7:8]
  p = exp(pars[9])/(1+exp(pars[9]))
  
  rho = exp(pars[10])/(1+exp(pars[10]))
  
  xsi[2] = exp(pars[11])/(1+exp(pars[11]))
  
  classes <- ifelse(p_draws<p, 1,2)
    
  m_pred = alpha * x + lambdas[classes]
  
  ll1 = -sum(dnorm(m-m_pred, mean=0, sd=xsi[2], log=TRUE))
  
  y_pred = beta[1] + beta[2]*m_pred + beta[3] * z + gamma * x + rho * (m - m_pred)
  
  ll2 = -sum(dnorm(y-y_pred, mean=0, sd=xsi[1], log=TRUE))
  
  ll1 + ll2
}

library(stats4)

MLE = optim(c(0,0,0,0,0,0,0,0,0,0,0), fn = neg_log_lik_gaussian_liv,
            method = 'L-BFGS-B',
            lower = .00001)

names(MLE$par) <- c('beta1','beta2','beta3','gamma','xsi1', 'alpha','lambda1','lambda2', 'prob_classmembership', 'rho', 'xsi2')

MLE


```

- Parameters are "off"
- Some parameters do not get estimates
- I am quite confident I simulated the data correctly. I think my LIV likelihood function is incorrect.