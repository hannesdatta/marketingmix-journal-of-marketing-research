---
title: "GfK Singapore - Results"
output:
  html_document: default
date: "`r format(Sys.time(), '%d %B %Y')`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

libs_to_load <- c('data.table', 'stargazer', 'knitr', 'xtable', 'car', 'kableExtra', 'stringi', 'ggplot2', 'ggpubr', 'plyr', 'gridExtra', 'grid', 'lme4', 'sjstats', 'ggthemes') #'blme' 

for (lib in libs_to_load) eval(parse(text=paste('library(', lib, ')')))

options(xtable.comment = FALSE)
options(knitr.kable.NA = '')

# Load data set
  brand_panel=fread('../../analysis/temp/preclean_main.csv')
  brand_panel[, ':=' (date = as.Date(date))]
  
# Load auxilary functions
  source('proc_auxilary.R')
  source('proc_rename.R')

# Load results
  load('app/app_workspace.RData')
  
  predictions <- fread('../output/predictions_within.csv')
  predictions_kfold = fread('../output/predictions_kfold.csv')
  
  elast <- elasticities$ec_main_sur 
  #elast <- elasticities$ec_main_w_novelty_sur 
  
  elast[, list(.N),by=c('category','country','brand')]
    
  # set order of variables to appear in figures and tables
  ordered_vars =  c('llen', 'rwpspr', 'wpswdst', 'nov6sh')
  ordered_vars = ordered_vars[which(ordered_vars%in%elast$variable)]
  
  names(ordered_vars) <- paste0(unlist(sanitize_table(data.frame(gsub('^ln', '', ordered_vars)))), ' elasticity')
  
  lmerctrl = lmerControl(optimizer ="Nelder_Mead", check.conv.singular="ignore")


winsor_p=.01

notes_sig = 'Significance levels: \\* *p*<.1, \\*\\* *p*<.05, \\*\\*\\* *p*<.01 (two-sided).'
  
for (dframe in grep('^elast$', ls(),value=T)) {
  print(dframe)
  for (.var in c('elast', 'elastlt')) {
    eval(parse(text=paste0(dframe,"[!is.na(get(.var)), paste0('w_', .var) := 1/get(paste0(.var, '_se'))]")))
    # rescale
    eval(parse(text=paste0(dframe,"[!is.na(get(.var)), paste0('w_', .var) := get(paste0('w_', .var))/max(get(paste0('w_', .var)))]")))
    eval(parse(text=paste0(dframe,"[!is.na(get(.var)), paste0('z_', .var) := get(.var)/get(paste0(.var, '_se'))]")))
  }
}  

estimnote = paste0('Elasticities are weighted by inverse standard errors.')
estimnoteshort= 'weighted by inverse standard errors'


notes_base = paste0("^1^ Regression of long-term elasticities on explanatory variables and three random effects, for brands, categories, and countries, respectively. Estimated using a linear mixed-effects model. ", estimnote, " Continuous variables have been mean-centred. Standard errors in parentheses.")

notes_loglik = 'Log-likelihood ratio tests computed relative to preceding models.'

# order of covariates in models
covars = c("(Intercept)", 
           "emerging", "gdppercap_rev","gci_rev","hdi_rev",
           "sbbe_std_mc",
           "I(sbbe_std_mc * emerging)",
           "I(sbbe_std_mc * gdppercap_rev)",
           "I(sbbe_std_mc * gci_rev)",
           "I(sbbe_std_mc * hdi_rev)",
           "ln_herf_mc", "ln_market_growth_mc", "appliance", "ln_gini_mc", "local_to_market", "international", "mean_ms_mc")

sigvalue = .1
zval = qnorm(1-sigvalue/2)

```

# Data

```{r table1_countries, echo = FALSE}
tmp=unique(elast, by='country')[, c('country','penn_percapitargdpe2010','penn_growthrgdpe2010', 'ginicoef','pdi', 'uai','mas'),with=F]

setorderv(tmp, c('country'))

tmp=sanitize_table(tmp)

kable(tmp, format='html', digits=c(0,0,2,2,2,2,2), format.args = list(big.mark = ",", format ='f'), initial.zero = FALSE, caption=tab('Development indicators for countries in sample^1^')) %>%
        kable_styling() %>% footnote(number=c('Countries shown in alphabethical order. Sources to be updated.'))
```

<P style='page-break-before: always'>

```{r table2_category_overview, echo = FALSE}
tmp=data.table(elast)
tmp[, ncountries:=length(unique(country)),by=c('category')]

tmp=tmp[!grepl('allothers|unbranded', brand,ignore.case=T), list(brand_ms=mean(brand_ms), ncountries=mean(ncountries)), by = c('category', 'appliance', 'brand')]

setorderv(tmp, c('category', 'appliance', 'brand_ms'), order=-1L)
tmp[!brand%in%c('unbranded','local'), rank:=1:.N, by = c('category')]
tmp[, brand_include:= rank%in%1:5]

tmp=tmp[, list(cattype=ifelse(unique(appliance)==1, 'Appliances', 'Electronics'), ncountries=unique(ncountries), nbrandsdat=length(unique(brand)), exemplary_brand_names=paste0(my_capitalize(unique(brand[brand_include==T])), collapse=', ')), by='category']
tmp[, category:=tolower(category)]
tmp=sanitize_table(tmp)
setnames(tmp, 'Top 5 brands', 'Top 5 brands^2^')

tmp[, sort_category:=tolower(`Category`)]
setorder(tmp, sort_category)
tmp[, sort_category:=NULL]

kable(tmp, format='html', caption=tab('Category overview^1^')) %>%
        kable_styling() %>% footnote(number=c('Categories shown in alphabetical order.', 'Top 5 brands are determined on the basis of their average volume share across countries, and are listed in decreasing order of their market share.'))

```

<P style='page-break-before: always'>
# Results

```{r continue_with_selection, echo=FALSE}
elast_all=data.table(elast)
elast=elast[!is.na(country_of_origin)&!country_of_origin==''&!tolower(brand)%in%c('unbranded')]
#elast[,list(.N),by=c('category','country','brand')]

excluded_brands=setdiff(unique(elast_all$brand), unique(elast$brand))
excluded_brands<-unique(gsub('Allothers.*', 'Composite brands (allothers)', excluded_brands))


```

Reported for a sample of `r length(unique(elast$brand))` unique brands (excluding `r paste0(my_capitalize(excluded_brands), collapse=', ')`).


```{r elasts_full, echo=F,results='asis'}

out = lapply(list(st=c('elast', 'z_elast', 'w_elast'), lt = c('elastlt','z_elastlt','w_elastlt')), function(obj) {
  tmp = elast[!is.na(get(obj[1]))][, ':=' (val=get(obj[1]), val_z=get(obj[2]), val_w=get(obj[3]))]
  tmp=tmp[, list(Neffects=.N, 
   						  ftmelast = sum(val*val_w)/sum(val_w),
   						  median_elast = median(val), 
  						  interval90 = paste0('[',paste(sprintf("%.3f",quantile(val, c(.05,.95))),collapse=', '),']')),
  												#  perc_positive = length(which(val_z>=(zval)))/.N, 
  												#  perc_null = length(which(abs(val_z)<zval))/.N, 
  												#  perc_negative = length(which(val_z<=(-zval)))/.N), 
  												by=c('variable')]
  tmp=tmp[match(ordered_vars, variable)]
  setnames(tmp, 'variable', 'mmixinstr')
  return(tmp)
  })
  
iters = list(lt=c('lt', 'Long-term')) #st=c('st', 'Short-term'), 
for (iter in iters) {

  print(kable(sanitize_table(out[[iter[1]]]), digits=3, format='html', format.args = list(big.mark = ","),
        caption=tab(paste0(iter[2], ' elasticities by marketing-mix instrument^1^'),prefix='')) %>% kable_styling() %>% 
        footnote(number=c(paste0('Table reports ', tolower(iter[2]), ' elasticities. The number of observations differs slightly across marketing-mix instruments because some brands in some markets (category/country combinations) do not have variation in these variables.'), estimnote)))
  #cat("<P style='page-break-before: always'>")

  }

```




```{r elast_by_cc, echo=F,results='asis', include=TRUE, warnings = FALSE}

qval=qnorm(1-sigvalue/2)

for (byvar in c('country')) {
  tmp=elast[!is.na(elastlt), list(N=.N,
                                  elast = sum(elastlt*w_elastlt)/sum(w_elastlt),
                                  sig = signstars(sum(elastlt/elastlt_se,na.rm=T)/sqrt(.N)),
                                  percpos = round(100*length(which(abs(elastlt/elast_se)>=qval&elastlt>0))/.N,0),
                                  percneg = round(100*length(which(abs(elastlt/elast_se)>=qval&elastlt<0))/.N,0),
                                  percns = round(100*length(which(abs(elastlt/elast_se)<qval))/.N,0)),
                                  by=c('variable', byvar)]
  tmp[, lbl := paste0(sprintf("%.3f",elast), ' ', sig)]
  				
  tmp2 = melt(tmp, id.vars=c('variable','country'))
  setnames(tmp2, 'variable.1', 'par')
  keeppars=c('N', 'lbl','percpos','percneg','percns')
  tmp2 <- tmp2[par%in%keeppars]
  tmp2[, par:=factor(as.character(par),levels=keeppars)]
  tmp2[, variable:=factor(as.character(variable, levels=ordered))]
  
  
  setnames(tmp2, byvar, 'byvar')
  
  tmp=dcast(tmp2,byvar~variable+par)
  
  
  setnames(tmp, 'byvar', byvar)

  
  tmp=sanitize_table(tmp)
  #setorderv(tmp, colnames(tmp)[1])
  
  cat("<P style='page-break-before: always'>")
  {print(kable(tmp, digits=3, caption = tab(paste0('Long-term elasticities (means by ', byvar, ')^1^'), prefix=''), format='html', initial.zero = FALSE) %>% add_header_above(list(' '=1, 'Line length' =5, 'Price'=5, 'Distribution' = 5)) %>% kable_styling() %>% footnote(number=paste0(estimnote, ' Reported by ', ifelse(byvar=='country', 'countries', 'categories'), ' in alphabetical order.'))) 
  }
}

```	

```{r dorfmann steiner, echo=F,results='asis', include=TRUE}

tmp=elast[!is.na(elastlt), list(N=.N,
                                  elast = sum(elastlt*w_elastlt)/sum(w_elastlt)),
                                   by=c('variable', 'country')]
tmp2 = dcast.data.table(tmp,country~variable,value.var='elast')

tmp2[, llen_ratio_to_sales := llen/-rwpspr]
tmp2[, distr_ratio_to_sales := wpswdst/-rwpspr]

# get population
weights <- unique(elast[, c('country','penn_rgdpe2010',
                        'penn_pop2010'),with=F],by=c('country'))
#weights[, gdp:=gdppercapitacurrent2010 * population2010]

tmp3 <- merge(tmp2, weights, by=c('country'),all.x=T)

tmp3[, weights:=penn_rgdpe2010/sum(penn_rgdpe2010)]

tmp3[, avg_llen:=sum(llen_ratio_to_sales*weights)]
tmp3[, avg_dst:=sum(distr_ratio_to_sales*weights)]

tmp3[, llen_index:=100*llen_ratio_to_sales/avg_llen]
tmp3[, dst_index:=100*distr_ratio_to_sales/avg_dst]

tmp3[, weights:=NULL]
tmp3[, ':=' (avg_llen=NULL, avg_dst=NULL)]
tmp3[, ':=' (gdp2010prices2010=NULL, avg_dst=NULL)]
tmp3[, ':=' (gdppercapitacurrent2010=NULL, population2010=NULL)]
#tmp3[, gdp:=gdp/1E9]
tmp3[, ':=' (penn_rgdpe2010=NULL, penn_pop2010=NULL)]
#'Weights' = 1,

print(kable(sanitize_table(tmp3), digits=c(0,3,3,3, 3,3, 1,1), caption = tab(paste0('Allocation of Marketing Expenditures'), prefix=''), format='html', initial.zero = FALSE) %>% add_header_above(list(' '=1, 'Average Elasticities' = 3, 'Expenditure ratios'=2,  'Expenditure index' = 2)) %>% kable_styling() %>% footnote(number='Average elasticities are weighted by inverse standard errors of the brand- and category-specific effects. Expenditure ratios are calculated in line with Farley and Lehmann (1994, p. 119). Weights are equal to a country\'s GDP (expenditure-side real GDP at chained PPPs in 2010, our sample\'s midpoint). Expenditure indexes are equal to expenditure ratios divided by GDP-weighted averages x 100.'))
  

```
<P style='page-break-before: always'>


```{r reset, echo=FALSE,results='asis'}
tableno<<-0
figureno<<-0
cat("<P style='page-break-before: always'>")
  
```

# Appendix

```{r sample_origin, echo=FALSE, results='asis'}

cols =  c('country_of_origin')
tmp = elast[, list(.N), by = c('brand',cols)]
tmp = tmp[!grepl('alloth', brand)]
tmp[brand=='threed', brand:='3D']
tmp = tmp[, list(nbrands=length(unique(brand)), all_brands=paste(my_capitalize(brand)[order(brand)], collapse=', ')), by = cols]
tmp[country_of_origin==''|is.na(country_of_origin), country_of_origin := 'Country not available']
tmp[, country_of_origin:=my_capitalize(country_of_origin)]

setorderv(tmp, 'nbrands', order=-1L)
setcolorder(tmp, c('country_of_origin', 'nbrands', 'all_brands'))

tmp=sanitize_table(tmp)

kable(tmp, caption = tab('Country-of-origins for brands in sample^1^', prefix ='A'),format='html') %>%
        kable_styling() %>% footnote(number=paste0('Countries are ordered by the number of brands from a given country; brand names are listed alphabetically.'))

```

<P style='page-break-before: always'>

```{r VIFS, echo=FALSE,results='asis', include=FALSE}
if(0){
m1 = ~1+ appliance + ln_market_growth_mc + ln_market_herf_mc + local_to_market  + ln_brand_prindex_mean_mc + brandz

m<-lm(update(elast~., m1), data=elast[variable=='llen'])

frame1=data.frame(vif(m))
colnames(frame1) <- c('VIF')
frame1$variable=rownames(frame1)
rownames(frame1)<-NULL
frame1=frame1[, c('variable','VIF')]
frame1=sanitize_table(frame1)
cat("<P style='page-break-before: always'>")

if(0){
kable(frame1,format='html', caption = tab('Assessing multicollinearity^1^', prefix='A'))%>% kable_styling() %>% footnote(number=paste0('Table reports VIFs values calculated in regression models using main effects for all variables listed above (i.e., excluding brand, category, and country effects).'))
}
}
```

```{r overview2, echo=FALSE, results='asis'}
#elast_all
tmp = elast[, list(Nbrands = length(unique(brand))), by = c('category','country')]

tabl = dcast.data.table(tmp, category~country, value.var=c('Nbrands'))
rownames(tabl) <- NULL

tabl=sanitize_table(tabl)
tabl[, sort_category:=tolower(`Category`)]
setorder(tabl, sort_category)
tabl[, sort_category:=NULL]

kable(tabl, caption = tab('Overview of markets (category/country combination) in the sample (with number of selected brands used in model estimation indicated per cell^1^)', prefix='A'))%>% kable_styling() %>% footnote(number=paste0('Number of brands include the composite brand, which aggregates all brands with market shares lower than 1% in 5 consecutive years (4 years for tablets).'))

```

```{r overview_avgelast, echo=FALSE, results='asis'}
#elast_all
tmp = elast[, list(welast = sum(elastlt*w_elastlt)/sum(w_elastlt)), by = c('category','country', 'variable')]

for (i in ordered_vars) {
  
tabl = dcast.data.table(tmp[variable==i], category~country, value.var=c('welast'))
rownames(tabl) <- NULL

tabl=sanitize_table(tabl)
tabl[, sort_category:=tolower(`Category`)]
setorder(tabl, sort_category)
tabl[, sort_category:=NULL]

print(kable(tabl, digits =3, caption = tab(paste0('Mean ', tolower(names(ordered_vars)[ordered_vars==i]), ' by market (category/country combination)^1^'), prefix='A'))%>% kable_styling() %>% footnote(number=paste0('Elasticities weighted by inverse standard errors.')))
}

```

<P style='page-break-before: always'>

```{r attributes, echo = FALSE, results= 'asis'}

# for each category

attributes <- suppressWarnings(melt(brand_panel[!is.na(usales), c('category', grep('^attr', colnames(brand_panel),value=T)),with=F], id.vars=c('category')))

attributes[, na:=all(is.na(value)),by=c('category','variable')]

attr = attributes[na==F, list(nobs = .N, meancap=mean(value), sdcap=sd(value), mincap=min(value), maxcap=max(value)),by=c('category','variable')]
setorder(attr,category,variable)
.vars=c('nobs','meancap','sdcap', 'mincap', 'maxcap')
for (.var in .vars) attr[, (.var):=as.character(formatC(get(.var), big.mark=',',digits=ifelse(.var=='nobs', 0, 3), format = 'f'))]

attr<-attr[!grepl('freezernotestimable', variable)]
setnames(attr, 'variable','Attribute')
tabl=sanitize_table(attr)
tabl[, sort_category:=tolower(`Category`)]
tabl[, sort_attribute:=tolower(`Attribute`)]

setorder(tabl, sort_category, sort_attribute)
tabl[, sort_category:=NULL]
tabl[, sort_attribute:=NULL]


print(kable(tabl, digits=3, caption = tab('Overview of physical search attributes per category^1^', prefix='A')) %>% kable_styling() %>% footnote(number=c(paste0('The unit of analysis is the brand-month level. Indicator variables are either 0 or 1 at the SKU-month-level; when aggregating them to the brand-month level for the analysis, they are averaged and hence measure the share of a brand\'s SKUs that carry a particular product attribute.'))))
```


<P style='page-break-before: always'>


```{r summarystats_model, echo=FALSE, results= 'asis'}

covars_summary <- gsub('ln', '', c('usales', gsub('rwpspr', 'rwpsprd', ordered_vars)))

tmp=data.table(brand_panel)
nbrands=length(unique(brand_panel$brand))
nmarkets=length(unique(brand_panel$market_id))
nobs=nrow(tmp)

tmp=tmp[, lapply(.SD, function(x) c(median=median(x,na.rm=T),firstqnt=quantile(x,.25,na.rm=T),thirdqnt=quantile(x,.75,na.rm=T))), .SDcols=c(covars_summary)]


tmp[, var:=rep(c('median', 'firstqnt','thirdqnt'),1)]
tmp=melt(tmp, id.var=c('var'))

dtf=dcast(tmp, variable~var)
setcolorder(dtf, c('variable', rep(c('median', 'firstqnt','thirdqnt'),1)))

### add correlation
give_cor <- function(cordat=data.frame(brand_panel[, covars_summary,with=F])) {
  correl=cor(cordat,use='pairwise.complete')
  N=matrix(double(prod(dim(correl))),ncol=ncol(cordat))
  t=N
  p=N
  for (i in 1:nrow(correl)) {
    for (j in 1:ncol(correl)) {
      N[i,j]=length(which(complete.cases(cordat[,c(i,j)])))
      t[i,j]=sqrt(N[i,j]-2)*(correl[i,j]/sqrt(1-correl[i,j]^2))
      p[i,j]=dt(t[i,j], df=N[i,j]-2)
    }
  }
return(list(cor=correl,p=p))
}

correl = give_cor(data.frame(brand_panel[, covars_summary,with=F]))

#sink('../output/tableA4.txt')
#correl$cor
#correl$p
#sink()

dtf=cbind(dtf,correl$cor[,-ncol(correl$cor)])


dtf=sanitize_table(dtf)


print(kable(dtf, format='html', initial.zero = FALSE, digits=c(1,0,0,0,3,3,3),caption = tab(paste0('Summary statistics and correlations for variables in sales response model^1^'),prefix='A')) %>% kable_styling() %>% footnote(number=c(paste0('Summary statistics and correlations for variables (prior to the log-operation and mean-centering) are computed across ', prettyNum(nobs, big.mark = ','), ' observations in our sample.'),'Converted to USD.')))
      #
    #%>% add_header_above(c(" " = 1, "Summary statistics" = 3, "Correlations" = length(covars_summary)-1)))

```


```{r correl, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}

tmp = data.table(dcast(elast,category+country+brand~variable, value.var=c('elastlt')))

printtmp=tmp[, ordered_vars, with = F]#grep('elastlt[_]', colnames(tmp),value=T) ,with=F]


tmp2=corstars(printtmp, method=c("pearson"),removeTriangle=c('upper'),result='none')


kable(sanitize_table(tmp2), format='html', caption=tab('Correlation among long-term marketing-mix elasticities',prefix='A')) %>%
        kable_styling()



```


```{r elast_by_cc2, echo=F,results='asis', include=TRUE}

qval=qnorm(1-sigvalue/2)

for (byvar in c('category')) {
  tmp=elast[!is.na(elastlt), list(N=.N,
                                  elast = sum(elastlt*w_elastlt)/sum(w_elastlt),
                                  sig = signstars(sum(elastlt/elastlt_se,na.rm=T)/sqrt(.N)),
                                  percpos = round(100*length(which(abs(elastlt/elast_se)>=qval&elastlt>0))/.N,0),
                                  percneg = round(100*length(which(abs(elastlt/elast_se)>=qval&elastlt<0))/.N,0),
                                  percns = round(100*length(which(abs(elastlt/elast_se)<qval))/.N,0)),
                                  by=c('variable', byvar)]
  tmp[, lbl := paste0(sprintf("%.3f",elast), ' ', sig)]
  				
  tmp2 = melt(tmp, id.vars=c('variable',byvar))
  setnames(tmp2, 'variable.1', 'par')
  keeppars=c('N', 'lbl','percpos','percneg','percns')
  tmp2 <- tmp2[par%in%keeppars]
  tmp2[, par:=factor(as.character(par),levels=keeppars)]
  tmp2[, variable:=factor(as.character(variable, levels=ordered))]
  
  
  setnames(tmp2, byvar, 'byvar')
  
  tmp=dcast.data.table(tmp2,byvar~variable+par)
  
  
  setnames(tmp, 'byvar', byvar)
  
  
  tmp=sanitize_table(tmp)
  tmp[, varorder:=tolower(get(colnames(tmp)[1]))]
  setorder(tmp, varorder)
  tmp[, varorder:=NULL]
  
  cat("<P style='page-break-before: always'>")
  {print(kable(tmp, digits=3, caption = tab(paste0('Long-term elasticities (means by ', byvar, ')^1^'), prefix=''), format='html', initial.zero = FALSE) %>% add_header_above(list(' '=1, 'Line length' =5, 'Price'=5, 'Distribution' = 5)) %>% kable_styling() %>% footnote(number=paste0(estimnote, ' Reported by ', ifelse(byvar=='country', 'countries', 'categories'), ' in alphabetical order.'))) 
  }
}


```	

```{r elasticities_comparison, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
  

unitlist = list(
  list(
    units = c(
      'Advertising not included (focal model)' = 'ec_chinahk_withoutadv',
      'Advertising included' = 'ec_chinahk_withadv'
    ),
    title = 'Differences in Long-Term Elasticities in Models With and Without Advertising Spending^1^'
  ),
  list(
    units = c(
      'Estimated on split data set (early)' = 'ec_first60',
      'Estimated on split data set (late)' = 'ec_last60'
    ),
    title =  'Differences in Long-Term Elasticities Over Time^1^'
  ),
  list(
    units = c(
      'Estimated without product attributes (main model)' = 'ec_main_sur',
      'Estimated with product attributes' = 'ec_main_attributes'
    ),
    title =  'Differences With And Without Product Attributes^1^'
  )#,
 # list(
  #  units = c(
 #     'Error correction model' = 'ec_main_sur',
  #    'Market share attraction model' = 'marketshare'
 #   ),
 #   title =  'Differences in Long-Term Elasticities Between Model Specifications^1^'
 # )
)


for (u in unitlist) {
  units = u$units
  compare_elast = rbindlist(lapply(units, function(.unit) {
    return(data.table(elasticities[[.unit]])[, c('category',
                                     'country',
                                     'brand',
                                     'variable',
                                     'elastlt',
                                     'elastlt_se'), with = F][, ':=' (
                                       type = .unit,
                                       w_elastlt = 1 / elastlt_se,
                                       elastlt_z = elastlt / elastlt_se
                                     )])
  }))
  
  
  # keep only markets for which both estimates are available
  if (any(grepl('adv', units))) {
    compare_elast[, has_adv := any(grepl('adv', variable)), by = c('category', 'country', 'brand')]
    compare_elast <- compare_elast[has_adv == T]
  } else {
    compare_elast[, N := .N, by = c('category', 'country', 'brand', 'variable')]
  compare_elast <- compare_elast[N == 2][, N := NULL]
  
  }
  
  
  compare_elast[, ttest_indic := ifelse(type == units[2], T, F)]
  
  
  
  tmp = compare_elast[, list(
    N = .N,
    mean = sum(elastlt * w_elastlt) / sum(w_elastlt),
    rosenthal = signstars(sum(elastlt_z) / sqrt(length(which(
      !is.na(elastlt)
    ))))
  ), by = c('type', 'variable')]
  setnames(tmp, 'variable', 'vars')
  
  
  # t-tests
  ttests = rbindlist(lapply(grep(
    'adv',
    unique(tmp$vars),
    invert = T,
    value = T
  ), function(.v) {
    tmp2 = summary(lm(
      elastlt ~ 1 + ttest_indic,
      data = compare_elast,
      subset = variable == .v
    ))
    tmp3 = data.table(variable = .v, rbind(tmp2$coefficients[2, ]))
    setnames(tmp3, c('vars', 'est', 'se', 't', 'p'))
  }))
  
  tmp[, type := factor(as.character(type), levels = units)]
  
  
  tmpx = data.table(dcast(melt(tmp, id.vars = c('type', 'vars')), vars ~ type + variable))
  
  tmpx[, order := match(vars, c('radv', ordered_vars))]
  
  tmpx = merge(tmpx,
               ttests[, c('vars', 't', 'p')],
               by.x = 'vars',
               by.y = 'vars',
               all.x = T)
  setorder(tmpx, order)
  tmpx[, order := NULL]
  for (.v in grep('N$|mean$|est$|se$|t$|p$', colnames(tmpx), value = T))
    tmpx[, paste0(.v) := as.numeric(get(.v))]
  
  la = sanitize_table(tmpx)
  nheaders = c(' ', names(units), 'Tests on differences')
  headers = c(1, 3, 3, 2)
  names(headers) = nheaders
  
  
  print(
    kable(
      la,
      digits = 3,
      format = 'html',
      format.args = list(big.mark = ","),
      caption = tab(paste0(u$title), prefix = 'A')
    ) %>% kable_styling() %>% add_header_above(headers)
  )
}

```




```{r withinR2, results='asis', echo = FALSE, include = TRUE}

ord=c('ec_main', 
      'ec_nommix', 'ec_onlyllen', 'ec_onlypr','ec_onlydst',
      'ec_main_attributes',
      'ec_lntrend',
      'ec_noendogeneity',
      'ec_main_w_novelty',
      'ec_unrestrictedcompetition',
      'ec_log',
      #'ec_main_currweights',
      #'ec_log',
      'salesresponse_linear',
      'salesresponse_linear_noldv',
      'salesresponse_linear_onlyldv',
      'salesresponse_loglog',
      'salesresponse_loglog_noldv',
      'salesresponse_loglog_onlyldv')

sel_ord = ord

#sel_ord = unique(unlist(sapply(paste0(ord,'$|', ord,'_holdout'), grep, x= unique(predictions$type),value=T,simplify=F)))


#predictions

estim_size = predictions[, list(N=length(which(estim_set==T))),by=c('type', 'category','country','brand')]
setkey(estim_size, category,country,brand,type)

#predictions <- predictions[]

predictions[, ':=' (common_dv=as.numeric(NA),
                    common_dv_hat = as.numeric(NA))]

#predictions[type=='ec_log']

predictions[grepl('^ec', type)&grepl('log',type), ':=' (common_dv = exp(lnusales),
                                                        common_dv_hat = exp(lnusales_hat))]
predictions[grepl('^ec', type)&!grepl('log',type), ':=' (common_dv = usales,
                                                        common_dv_hat = usales_hat)]
predictions[grepl('^salesresponse', type)&grepl('log',type), ':=' (common_dv = exp(lnusales),
                                                        common_dv_hat = exp(dv_hat))]
predictions[grepl('^salesresponse', type)&!grepl('log',type), ':=' (common_dv = usales,
                                                        common_dv_hat = dv_hat)]


table(predictions$type)


# how to compare?
r2s=predictions[type%in%sel_ord, list(#R2_diff = cor(dlnusales, dlnusales_hat, use='pairwise')^2,
                       R2_lev = cor(common_dv, common_dv_hat, use='pairwise')^2,
                       #cor_diff = cor(dlnusales, dlnusales_hat, use='pairwise'),
                     # cor_lev = cor(lnusales, lnusales_hat, use='pairwise'),
                      # MSE_diff = mean((dlnusales_hat-dlnusales)^2,na.rm=T),
                       MSE_lev = mean((common_dv_hat-common_dv)^2,na.rm=T),
                     MAPE_lev = median(abs((common_dv-common_dv_hat)/common_dv),na.rm=T),
                     N=.N),
             by = c('type','category','country','brand')]

 setkey(r2s, category, country, brand, type)
  r2s[estim_size, N:=i.N]
  

  tmp = r2s[, lapply(.SD, mean,na.rm=T), by = c('type'), .SDcols=grep("(R2|MAPE).*lev$",colnames(r2s),value=T)]
  
  # --> investigate
  
  tmp[, ord:=match(type, ord)]
  
  setorder(tmp, ord)
  tmp[, ord:=NULL]
  lbl = 'Model selection (within model fit)'
  tmp2=tmp
  tmp2 = sanitize_table(tmp)
  setnames(tmp2, 'R2_lev', 'R2')
  setnames(tmp2, 'MAPE_lev', 'MeAPE')
  
  #setnames(tmp2, 'type', 'Model type')
  print(kable(tmp2, format= 'html', caption =lbl, digits = 3) %>% kable_styling()%>% footnote(number=paste0('R2 (MeAPE) is computed as the average squared correlation (average median percentage error) between predicted and observed sales, across the ', nrow(unique(predictions, by =c('category','brand','country'))), ' estimated models.'))) 

```

```{r holdoutrsq, results='asis', echo = FALSE, include= FALSE}

ord=ord 


tmppred = predictions_kfold[type%in%ord]

setorder(tmppred, type, category,country,brand,kfold,date)
tmppred[, type:=as.factor(type)]

tmppred[, ':=' (common_dv=as.numeric(NA),
                    common_dv_hat = as.numeric(NA))]

table(tmppred$type)

tmppred[grepl('^ec', type)&grepl('log',type), ':=' (common_dv = exp(lnusales),
                                                        common_dv_hat = exp(ldv+ddv_hat))]


tmppred[grepl('^ec', type)&!grepl('log',type), ':=' (common_dv = usales,
                                                        common_dv_hat = ldv + ddv_hat)]

tmppred[grepl('^salesresponse', type)&grepl('log',type), ':=' (common_dv = exp(lnusales),
                                                        common_dv_hat = exp(dv_hat))]
tmppred[grepl('^salesresponse', type)&!grepl('log',type), ':=' (common_dv = usales,
                                                        common_dv_hat = dv_hat)]

# measures defined for all models?
summary(tmppred$common_dv)

tmp = tmppred[, list(R2 = cor(common_dv, common_dv_hat, use='pairwise')^2,
                         RMSE = sqrt(mean((common_dv-common_dv_hat)^2,na.rm=T)),
                     MAPE = median(abs((common_dv-common_dv_hat)/common_dv),na.rm=T)),
                  by=c('type','category','country','brand','kfold','estim_set')]

# ADD TRAINING AND PREDICTION TO SET
# correct predictions
sel_ord=ord
tmp2=tmp[type%in%sel_ord, lapply(.SD, mean), by = c('type', 'estim_set'), .SDcols=grep("R2|mse|mape", colnames(tmp),value=T, ignore.case=T)]
tmp2[, type2:=factor(ifelse(estim_set==T, 'training','holdout'), levels=c('training','holdout'))]
tmp3 = dcast(melt(tmp2, id.vars=c('type','type2', 'estim_set')), type~variable+type2)

tmp3[, ord:=match(type, ord)]
  
setorder(tmp3, ord)
tmp3[, ord:=NULL]

lbl = 'Model selection (hold-out sample)'
  
  tmp4 = sanitize_table(tmp3)
 # setnames(tmp2, 'R2_lev', 'R2')
 # setnames(tmp2, 'MSE_lev', 'MSE')
  
  setnames(tmp4, 'type', 'Model type')
  print(kable(tmp4, format= 'html', caption =lbl, digits = 3) %>% add_header_above(list(' '=1, 'R-squared' =2, 'RMSE'=2, 'MeAPE' = 2)))
  
  


```


```{r,echo=FALSE, include=TRUE}


r2=tmppred[estim_set==F&type=='ec_main', list(r2=cor(common_dv, common_dv_hat, use='pairwise')^2), by = c('category','country','brand')]

setorder(r2, r2)


r2x=tmppred[estim_set==F&type=='ec_main'& brand =='samsung' & category=='phones_smart'&country=='china']


r2x[,date:=as.Date(date)]

# selection
#with(r2x, plot(date, common_dv, lty=1,lwd=2,type='c', main = 'Predicted versus fitted values', xlab = 'Date',ylab='Unit sales'))
#with(r2x, lines(date, common_dv_hat, lty=2, type = 'c'))

library(ggplot2)
ggplot() + geom_line(data=r2x, aes(date, common_dv)) +
  geom_line(data=r2x, linetype = 2, aes(date, common_dv_hat)) + scale_x_date(date_labels = "%b-%Y") + ylab('Unit sales') + xlab('Date')

```

```{r,echo=FALSE, include=TRUE}


r2=predictions[type=='ec_main', list(r2=cor(common_dv, common_dv_hat, use='pairwise')^2), by = c('category','country','brand')]

setorder(r2, r2)


r2x=predictions[type=='ec_main'& brand =='samsung' & category=='phones_smart'&country=='china']


r2x[,date:=as.Date(date)]

# selection
#with(r2x, plot(date, common_dv, lty=1,lwd=2,type='c', main = 'Predicted versus fitted values', xlab = 'Date',ylab='Unit sales'))
#with(r2x, lines(date, common_dv_hat, lty=2, type = 'c'))


r2x <- r2x[complete.cases(r2x[, c('common_dv','common_dv_hat'),with=F]),]

#dates = seq(from=min(r2x$date), to=max(r2x$date), by = "month")

#df <- data.frame(dates, y)  

# use the format you need in your plot using scale_x_date
library(ggplot2)
ggplot() + geom_line(data=r2x, aes(date, common_dv)) +
  geom_line(data=r2x, linetype = 2, aes(date, common_dv_hat)) + scale_x_date(date_labels = "%b-%Y") + ylab('Unit sales') + xlab('Date')

#  geom_line(data = prescription2, aes(x = dates, y = Difference), color = "red") +

#+
#sgeom_vline(xintercept = as.Date("01-01-2012",  format = "%d-%m-%Y"), linetype = 'dotted', color = 'blue')

```


```{r coefvar_by_cc2, echo=F,results='asis', include=FALSE}

qval=qnorm(1-sigvalue/2)

CV = lapply(c('category','country'), function(byvar) {

 
tmp=elast[!is.na(elastlt), list(N=.N,
                                  elast = sum(elastlt*w_elastlt)/sum(w_elastlt)),
                                   by=c('variable', byvar)]
tmp[, list(CV=sd(elast)/mean(elast)),by=c('variable')][, byvar:=byvar]

})

cv2=rbindlist(CV)

tmp=dcast(cv2, variable~byvar, value.var='CV')
  tmp=sanitize_table(tmp)
 
  cat("<P style='page-break-before: always'>")
  print(kable(tmp, digits=3, caption = tab(paste0('Coefficient of variation (CV) by Category and Country')), format='html', initial.zero = FALSE) %>% kable_styling() %>% footnote(number='Computed on the basis of weighted elasticities'))
  
# pooled
  
tmp=elast[!is.na(elastlt), list(CV = sd(elastlt)/mean(elastlt)), by = c('variable')]
print(kable(tmp))




```	
